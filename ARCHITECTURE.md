# System Architecture & Data Flow

## ğŸ—ï¸ Overall Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        USER BROWSER (Client)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  React SPA (localhost:5173)                                   â”‚ â”‚
â”‚  â”‚  â”œâ”€ Pages: Home, Monitor, Analytics, Report                  â”‚ â”‚
â”‚  â”‚  â”œâ”€ Components: LiveMonitoring, VideoUpload, Dashboard       â”‚ â”‚
â”‚  â”‚  â”œâ”€ Charts: Bar, Pie, Line (Recharts)                        â”‚ â”‚
â”‚  â”‚  â””â”€ State Management: React Hooks (useState, useEffect)      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    HTTP REST API (Axios, JSON)
                                 â”‚
                                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BACKEND SERVER (FastAPI)                        â”‚
â”‚                      (localhost:8000)                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ API Routes (CORS enabled)                                     â”‚ â”‚
â”‚  â”œâ”€ POST /monitoring/frame â†’ analyze single image               â”‚ â”‚
â”‚  â”œâ”€ POST /monitoring/upload-video/ â†’ analyze video file         â”‚ â”‚
â”‚  â”œâ”€ POST /monitoring/analytics â†’ compute insights               â”‚ â”‚
â”‚  â””â”€ GET /monitoring/health â†’ service status                     â”‚ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Services                                                      â”‚ â”‚
â”‚  â”œâ”€ emotion_service.py â†’ process_frame()                        â”‚ â”‚
â”‚  â”‚   â”œâ”€ Face detection with YOLOv1 model                        â”‚ â”‚
â”‚  â”‚   â”œâ”€ Emotion classification with YOLOv1                      â”‚ â”‚
â”‚  â”‚   â”œâ”€ Bounding box + confidence extraction                    â”‚ â”‚
â”‚  â”‚   â””â”€ Emotion distribution calculation                        â”‚ â”‚
â”‚  â”œâ”€ ai_service.py â†’ get_models()                                â”‚ â”‚
â”‚  â”‚   â”œâ”€ Load face_detection.pt                                  â”‚ â”‚
â”‚  â”‚   â”œâ”€ Load fer_YOLOv1.pt                                      â”‚ â”‚
â”‚  â”‚   â””â”€ Cache models in memory                                  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Utilities                                                     â”‚ â”‚
â”‚  â”œâ”€ Video Decoding (OpenCV + imageio fallback)                  â”‚ â”‚
â”‚  â”œâ”€ Frame Extraction (every N frames)                           â”‚ â”‚
â”‚  â”œâ”€ Image Preprocessing (resize, normalize)                     â”‚ â”‚
â”‚  â””â”€ Error Handling & Logging                                    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                      Deep Learning Model Loading
                                 â”‚
                                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DEEP LEARNING MODELS                             â”‚
â”‚                     (Ultralytics YOLOv1)                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Model 1: Face Detection (face_detection.pt)                  â”‚ â”‚
â”‚  â”œâ”€ Input: BGR Image (H Ã— W Ã— 3)                                â”‚ â”‚
â”‚  â”œâ”€ Process: YOLO inference at 640px resolution                 â”‚ â”‚
â”‚  â”œâ”€ Output: Bounding boxes [x1, y1, x2, y2] with confidence    â”‚ â”‚
â”‚  â””â”€ Backend: PyTorch or ONNX runtime                            â”‚ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Model 2: Emotion Recognition (fer_YOLOv1.pt)                â”‚ â”‚
â”‚  â”œâ”€ Input: Cropped face region (416 Ã— 416)                      â”‚ â”‚
â”‚  â”œâ”€ Process: Preprocess â†’ YOLO inference â†’ emotion class        â”‚ â”‚
â”‚  â”œâ”€ Output: Emotion label (7 classes)                           â”‚ â”‚
â”‚  â”‚   Classes: Anger, Disgust, Fear, Happy, Neutral, Sad,       â”‚ â”‚
â”‚  â”‚            Surprise                                          â”‚ â”‚
â”‚  â””â”€ Backend: PyTorch or ONNX runtime                            â”‚ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Model 3: Backup (fer2013_mini_XCEPTION.hdf5)               â”‚ â”‚
â”‚  â”œâ”€ Keras/TensorFlow model (optional fallback)                  â”‚ â”‚
â”‚  â””â”€ Can be used if YOLO inference fails                         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Data Flow Diagrams

### Live Monitoring Flow

```
START Webcam Stream
    â”‚
    â”œâ”€ navigator.mediaDevices.getUserMedia({video: true})
    â”‚  â””â”€ Get camera permission
    â”‚
    â”œâ”€ Set video.srcObject = stream
    â”‚
    â”œâ”€ Draw video frame to Canvas element
    â”‚
    â”œâ”€ Convert Canvas â†’ JPEG blob (0.8 quality)
    â”‚
    â”œâ”€ Create FormData, append blob as "file"
    â”‚
    â”œâ”€ POST http://localhost:8000/monitoring/frame
    â”‚  â”‚
    â”‚  â””â”€ BACKEND PROCESSING:
    â”‚     â”œâ”€ Read image bytes
    â”‚     â”œâ”€ Decode to OpenCV BGR format
    â”‚     â”œâ”€ Run face detection model (640px)
    â”‚     â”œâ”€ For each detected face:
    â”‚     â”‚  â”œâ”€ Crop face region
    â”‚     â”‚  â”œâ”€ Resize to 416Ã—416
    â”‚     â”‚  â”œâ”€ Normalize pixel values
    â”‚     â”‚  â”œâ”€ Run emotion model
    â”‚     â”‚  â””â”€ Get emotion class + confidence
    â”‚     â”œâ”€ Count emotion distribution
    â”‚     â”œâ”€ Calculate positive rate
    â”‚     â”œâ”€ Get dominant emotion
    â”‚     â””â”€ Return JSON response
    â”‚
    â”œâ”€ FRONTEND RECEIVES:
    â”‚  {
    â”‚    "faces": [
    â”‚      {"bbox": [x1,y1,x2,y2], "emotion": "Happy", "confidence": 0.95},
    â”‚      {...}
    â”‚    ],
    â”‚    "emotion_distribution": {"Happy": 3, "Neutral": 1, ...},
    â”‚    "current_emotion": "Happy",
    â”‚    "positive_rate": 75
    â”‚  }
    â”‚
    â”œâ”€ Update React state (setCurrentEmotion, setPositiveRate, etc.)
    â”‚
    â”œâ”€ Update UI:
    â”‚  â”œâ”€ Large emotion display with color
    â”‚  â”œâ”€ Positive rate progress bar
    â”‚  â”œâ”€ Face count badge
    â”‚  â””â”€ Emotion distribution mini-chart
    â”‚
    â”œâ”€ Schedule next analysis in 500ms
    â”‚
    â””â”€ REPEAT until Stop clicked

STOP Webcam Stream
    â”œâ”€ Stop all setTimeout callbacks
    â”œâ”€ Release camera stream (getTracks().stop())
    â””â”€ Clean up resources
```

### Video Analysis Flow

```
SELECT Video File
    â”‚
    â”œâ”€ Validate:
    â”‚  â”œâ”€ Type: MP4, AVI, MOV
    â”‚  â””â”€ Size: < 500MB
    â”‚
    â”œâ”€ Create FormData with file + frame_step=5
    â”‚
    â”œâ”€ POST http://localhost:8000/monitoring/upload-video/
    â”‚  â”‚
    â”‚  â””â”€ BACKEND PROCESSING:
    â”‚     â”œâ”€ Save bytes to temporary file
    â”‚     â”‚
    â”‚     â”œâ”€ Try OpenCV: cv2.VideoCapture(temp_path)
    â”‚     â”‚  OR
    â”‚     â”‚  Fallback to imageio.get_reader()
    â”‚     â”‚
    â”‚     â”œâ”€ Get total frame count
    â”‚     â”‚
    â”‚     â”œâ”€ FOR each frame in video (step=5):
    â”‚     â”‚  â”œâ”€ Extract frame
    â”‚     â”‚  â”œâ”€ Convert RGBâ†’BGR if needed
    â”‚     â”‚  â”œâ”€ Call process_frame(frame)
    â”‚     â”‚  â”‚  â”œâ”€ Detect faces
    â”‚     â”‚  â”‚  â”œâ”€ Recognize emotions
    â”‚     â”‚  â”‚  â””â”€ Get results
    â”‚     â”‚  â”‚
    â”‚     â”‚  â”œâ”€ Append to timeline:
    â”‚     â”‚  â”‚  {
    â”‚     â”‚  â”‚    "frame": 0,
    â”‚     â”‚  â”‚    "current_emotion": "Happy",
    â”‚     â”‚  â”‚    "positive_rate": 80,
    â”‚     â”‚  â”‚    "emotion_distribution": {...}
    â”‚     â”‚  â”‚  }
    â”‚     â”‚  â”‚
    â”‚     â”‚  â””â”€ Log progress
    â”‚     â”‚
    â”‚     â”œâ”€ Delete temporary file
    â”‚     â”‚
    â”‚     â””â”€ Return:
    â”‚        {
    â”‚          "frames_total": 300,
    â”‚          "frames_analyzed": 60,
    â”‚          "timeline": [...]
    â”‚        }
    â”‚
    â”œâ”€ FRONTEND RECEIVES timeline
    â”‚
    â”œâ”€ Store in state: setAnalysisData(data)
    â”‚
    â”œâ”€ Automatically switch to Analytics tab
    â”‚
    â””â”€ POST to /monitoring/analytics
       â”‚
       â””â”€ BACKEND COMPUTING INSIGHTS:
          â”œâ”€ Aggregate emotion_distribution from all frames
          â”œâ”€ Count positive emotions (Happy + Surprise)
          â”œâ”€ Calculate positive_rate percentage
          â”œâ”€ Find dominant_emotion (max count)
          â”œâ”€ Build emotion_over_time timeline
          â”œâ”€ Generate teaching_insights:
          â”‚  â”œâ”€ If positive_rate >= 75%
          â”‚  â”‚  â””â”€ "âœ… Lá»›p ráº¥t há»©ng thÃº..."
          â”‚  â”œâ”€ If positive_rate >= 50%
          â”‚  â”‚  â””â”€ "ğŸ‘ Lá»›p cÃ³ há»©ng thÃº tá»‘t..."
          â”‚  â””â”€ etc.
          â”‚
          â””â”€ Return:
             {
               "total_samples": 60,
               "dominant_emotion": "Happy",
               "positive_rate": 75,
               "emotion_distribution": {...},
               "emotion_over_time": [...],
               "teaching_insights": [...]
             }

DISPLAY Analytics Dashboard:
    â”œâ”€ Bar Chart: Emotion distribution (count per emotion)
    â”œâ”€ Pie Chart: Emotion breakdown (percentages)
    â”œâ”€ Line Chart: Positive rate over time (by frame)
    â”œâ”€ Stat Cards: Samples, dominant emotion, positive rate
    â”œâ”€ Teaching Insights: Recommendations
    â””â”€ Export button (for future enhancement)
```

### Component Hierarchy

```
App (Router, Protected Routes)
â”œâ”€ NavBar (when logged in)
â”‚
â””â”€ MonitorPage (Main page with tabs)
   â”œâ”€ Tab 1: Live Monitoring
   â”‚  â””â”€ LiveMonitoring Component
   â”‚     â”œâ”€ useRef: videoRef, canvasRef
   â”‚     â”œâ”€ useState: isStreaming, currentEmotion, emotionDist
   â”‚     â”œâ”€ useEffect: cleanup on unmount
   â”‚     â”œâ”€ Functions:
   â”‚     â”‚  â”œâ”€ startStream() â†’ navigator.mediaDevices.getUserMedia()
   â”‚     â”‚  â”œâ”€ stopStream() â†’ stream.getTracks().stop()
   â”‚     â”‚  â””â”€ analyzeVideo() â†’ axios.post(/frame)
   â”‚     â”‚
   â”‚     â””â”€ JSX:
   â”‚        â”œâ”€ <video> element (videoRef)
   â”‚        â”œâ”€ <canvas> element (canvasRef, hidden)
   â”‚        â”œâ”€ Start/Stop buttons
   â”‚        â”œâ”€ Emotion display card
   â”‚        â”œâ”€ Positive rate progress bar
   â”‚        â””â”€ Emotion distribution chart
   â”‚
   â”œâ”€ Tab 2: Video Upload
   â”‚  â””â”€ VideoUpload Component
   â”‚     â”œâ”€ useState: file, loading, progress, result
   â”‚     â”œâ”€ Functions:
   â”‚     â”‚  â”œâ”€ handleFileChange() â†’ validate file
   â”‚     â”‚  â”œâ”€ handleUpload() â†’ axios.post(/upload-video)
   â”‚     â”‚  â””â”€ onAnalysisComplete callback
   â”‚     â”‚
   â”‚     â””â”€ JSX:
   â”‚        â”œâ”€ <input type="file">
   â”‚        â”œâ”€ File info display
   â”‚        â”œâ”€ Progress bar
   â”‚        â”œâ”€ Upload button
   â”‚        â””â”€ Result summary
   â”‚
   â””â”€ Tab 3: Analytics
      â””â”€ AnalyticsDashboard Component
         â”œâ”€ Props: analysisData
         â”œâ”€ useState: analytics, loading
         â”œâ”€ useEffect: fetch analytics when data changes
         â”œâ”€ Functions:
         â”‚  â”œâ”€ fetchAnalytics() â†’ axios.post(/analytics)
         â”‚
         â””â”€ JSX:
            â”œâ”€ Summary stats (3 cards)
            â”œâ”€ Teaching insights box
            â”œâ”€ Bar chart (Recharts)
            â”œâ”€ Pie chart (Recharts)
            â”œâ”€ Line chart (Recharts)
            â””â”€ Export button
```

---

## ğŸ”„ State Management

```
MonitorPage State:
â”œâ”€ activeTab: 'live' | 'upload' | 'analytics'
â””â”€ analysisData: null | {frames_total, frames_analyzed, timeline}

LiveMonitoring State:
â”œâ”€ isStreaming: boolean
â”œâ”€ currentEmotion: string
â”œâ”€ positiveRate: number
â”œâ”€ faceCount: number
â””â”€ emotionDist: {emotion: count}

VideoUpload State:
â”œâ”€ file: null | File
â”œâ”€ loading: boolean
â”œâ”€ progress: 0-100
â”œâ”€ error: null | string
â””â”€ result: null | {frames_total, frames_analyzed}

AnalyticsDashboard State:
â”œâ”€ analytics: null | {total_samples, dominant_emotion, ...}
â”œâ”€ loading: boolean
â””â”€ error: null | string
```

---

## ğŸ—‚ï¸ Database Schema (Future)

```sql
-- Sessions (Buá»•i há»c)
CREATE TABLE sessions (
  id BIGINT PRIMARY KEY,
  teacher_id BIGINT REFERENCES users(id),
  subject VARCHAR(255),
  created_at TIMESTAMP DEFAULT NOW()
);

-- Emotion Readings (Dá»¯ liá»‡u cáº£m xÃºc)
CREATE TABLE emotion_readings (
  id BIGINT PRIMARY KEY,
  session_id BIGINT REFERENCES sessions(id),
  timestamp TIMESTAMP DEFAULT NOW(),
  emotion VARCHAR(50),
  confidence FLOAT,
  face_count INT,
  image_path TEXT
);

-- Session Notes (Ghi chÃº buá»•i há»c)
CREATE TABLE session_notes (
  id BIGINT PRIMARY KEY,
  session_id BIGINT UNIQUE REFERENCES sessions(id),
  summary TEXT,
  notes TEXT
);

-- Session Reports (BÃ¡o cÃ¡o)
CREATE TABLE session_reports (
  id BIGINT PRIMARY KEY,
  session_id BIGINT REFERENCES sessions(id),
  file_path TEXT NOT NULL,
  exported_by BIGINT REFERENCES users(id),
  created_at TIMESTAMP DEFAULT NOW()
);
```

---

## ğŸš€ Deployment Architecture

```
PRODUCTION SETUP:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          NGINX Reverse Proxy                 â”‚
â”‚     (Port 80/443 - Public facing)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                â”‚
       â†“                â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚Frontendâ”‚      â”‚ Backend  â”‚
   â”‚ Cont.  â”‚      â”‚ Cont.    â”‚
   â”‚Node.js â”‚      â”‚ Uvicorn  â”‚
   â”‚ :5173  â”‚      â”‚ :8000    â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Docker Volume   â”‚
            â”‚  (Models, Data)  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¡ API Response Timeline

```
Client Request Timeline:

t=0ms     POST /monitoring/frame
          â””â”€ Browser sends image blob

t=10ms    Backend receives request
          â””â”€ Decode image bytes

t=15ms    Face detection inference
          â””â”€ YOLO on 640px image

t=25ms    Emotion detection per face (Ã—N faces)
          â””â”€ YOLO on 416px crops

t=40ms    Result aggregation
          â””â”€ Compute distribution, positive rate

t=45ms    Response sent
          â””â”€ JSON response to client

t=50ms    Frontend updates state
          â””â”€ React re-render

t=55ms    UI animation completes
          â””â”€ Emotion display updates

TOTAL: ~50-100ms (depending on GPU availability)
```

---

## ğŸ” Security Considerations

```
Current (Development):
â”œâ”€ CORS: Allow "*" (all origins)
â”œâ”€ Auth: None (demo mode)
â””â”€ HTTPS: Not used

Production (Recommended):
â”œâ”€ CORS: Whitelist specific origins
â”œâ”€ Auth: JWT tokens, role-based access
â”œâ”€ HTTPS: Required (self-signed or Let's Encrypt)
â”œâ”€ Rate limiting: Prevent abuse
â”œâ”€ Input validation: File type, size, content
â”œâ”€ Model security: No direct model access
â””â”€ Data encryption: Sensitive data at rest/transit
```

---

This architecture document provides a complete picture of:

- System components and their relationships
- Data flow through the entire pipeline
- Component hierarchy and state management
- Database schema for future enhancement
- Deployment considerations
- Performance characteristics
